<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/poole_hyde.css"> <link rel=stylesheet  href="/css/sisap.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/assets/favicon.png"> <title>LAION2B Dataset</title> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <img alt="sisap logo" src="https://www.sisap.org/2023/images/sisap.png" /> <h1><a href="/">SISAP Indexing challenge</a></h1> <p class=lead >challenge</p> </div> <nav class=sidebar-nav > <a class="sidebar-nav-item " href="/">Home</a> <!--a class="sidebar-nav-item {{ispage 2025/evaluationmethodology/*}}active{{end}}" href="/2025/evaluationmethodology/">Methodology</a> <a class="sidebar-nav-item {{ispage 2025/datasets/*}}active{{end}}" href="/2025/datasets/">Datasets</a> <a class="sidebar-nav-item {{ispage 2025/repoexamples/*}}active{{end}}" href="/2025/repoexamples/">Repository examples</a> --> <!--a class="sidebar-nav-item {{ispage ioformats/*}}active{{end}}" href="/ioformats/">Inputs and outputs</a--> <a class="sidebar-nav-item " href="/2024/">2024 edition</a> <a class="sidebar-nav-item active" href="/2023/">2023 edition</a> </nav> <p>&copy; sisap challenge committee.</p> </div> </div> <div class="content container"> <div class=franklin-content > <div><span>2023 edition: </span> <a href="/2023/tasks/">Tasks</a> | <a href="/2023/evaluationmethodology/">Methodology</a> | <a href="/2023/datasets/">Datasets</a> | <a href="/2023/repoexamples/">Repository examples</a> | <a href="/2023/committee/">Committee and pre-registration</a> </div> <h1 id=the_laion2b_and_projections ><a href="#the_laion2b_and_projections" class=header-anchor >The LAION2B and projections</a></h1> <div class=franklin-toc ><ol><li><a href="#about_the_laion5b">About the LAION5B</a><ol><li><a href="#subset_of_the_challenge">Subset of the challenge</a></ol><li><a href="#subsets">Subsets</a><li><a href="#768d_clip_embeddings_clip768">768d clip embeddings &#40;clip768&#41;</a><li><a href="#32d_pca_projections_pca32">32d PCA projections &#40;pca32&#41;</a><li><a href="#96d_pca_projections_pca96">96d PCA projections &#40;pca96&#41;</a><li><a href="#1024-bit_binary_sketches_hamming">1024-bit binary sketches &#40;hamming&#41;</a><li><a href="#gold_standard_list_computed_with_32-bit_floating_point_arithmetic_100_nearest_neighbors">Gold standard list &#40;computed with 32-bit floating point arithmetic, 100 nearest neighbors&#41;</a><li><a href="#gold_standard_for_public_queries_computed_with_64-bit_ieee_floating_point_arithmetic_1000_nearest_neighbors">Gold standard for public queries &#40;computed with 64-bit IEEE floating point arithmetic, 1000 nearest neighbors&#41;</a><li><a href="#gold_standard_for_private_queries_computed_with_64-bit_ieee_floating_point_arithmetic_1000_nearest_neighbors">Gold standard for private queries &#40;computed with 64-bit IEEE floating point arithmetic, 1000 nearest neighbors&#41;</a></ol></div> <h2 id=about_the_laion5b ><a href="#about_the_laion5b" class=header-anchor >About the LAION5B</a></h2> <p>The <strong>LAION5B</strong> dataset is an openly available image collection that has been used for learning very large visual and language deep-neural models; for instance, the famed stable diffusion generative model used it as the training set. The collection equips each image with a URL handle, allowing people to showcase demonstrations easily.</p> <p>A more detailed description can be found here:</p> <div class=important ><em>Schuhmann, C., Beaumont, R., Vencu, R., Gordon, C., Wightman, R., Cherti, M., ... &amp; Jitsev, J. &#40;2022&#41;. Laion-5b: An open large-scale dataset for training next generation image-text models. arXiv preprint arXiv:2210.08402.</em></div> <p>The English subset, often called LAION2B, contains over 2 billion objects.</p> <h3 id=subset_of_the_challenge ><a href="#subset_of_the_challenge" class=header-anchor >Subset of the challenge</a></h3> <p>The dataset is divided into parts containing close to 1M vectors. We selected the first 112 parts &#40;0000 to 0111&#41;; we used the first part to extract the public query set and the rest to extract the database. The subset use approximately 160GB of space and its associated metadata 20GB &#40;the first 112 parts&#41;. Embeddings are distributed using single precision &#40;16bits&#41; floating point vectors bundled in the NumPy data-specific format <code>.npz</code>. They can be loaded on most platforms due to the format&#39;s popularity.</p> <p>The challenge has three subsets:</p> <ul> <li><p>10M subset: concatenation of 1-11 parts.</p> <li><p>30M subset: concatenation of 1-33 parts.</p> <li><p>100M subset: concatenation of 1-111 parts.</p> <li><p>public queries: computed from part 0.</p> </ul> <p>All parts should be concatenated in order and also removing NSFW entries &#40;marked in metadata files&#41;.</p> <ul> <li><p><strong>Note 1</strong>: You will get 768 dimensional 16-bit floating point vectors that may be changed to a 32-bit format to get full speed on legacy hardware.</p> <li><p><strong>Note 2</strong>: Our gold-standards were computed using <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>-normalized vectors &#40;i.e., unitary norms&#41; and the <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>cos</mi><mo>⁡</mo><mo stretchy=false >(</mo><mo>⋅</mo><mo separator=true >,</mo><mo>⋅</mo><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">1-\cos(\cdot, \cdot)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7278em;vertical-align:-0.0833em;"></span><span class=mord >1</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >−</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mop >cos</span><span class=mopen >(</span><span class=mord >⋅</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >⋅</span><span class=mclose >)</span></span></span></span> as distance function.</p> <li><p><strong>Note 3</strong>: Our gold-standard <code>.h5</code> files contain the 100 nearest neighbors of each query using two associated matrices <code>knns</code> and <code>dists</code>, i.e., columns correspond to queries and rows to nearest neighbors for each query.</p> <ul> <li><p>The <code>knns</code> identifiers start indexing on 1.</p> <li><p>The <code>dists</code> contains raw distance values for each corresponding query and object, i.e., <code>1-\cos&#40;\cdot, \cdot&#41;</code>; please consider that this is not a proper metric distance. People using metric properties can use the angle with minor changes. </p> </ul> </ul> <h2 id=subsets ><a href="#subsets" class=header-anchor >Subsets</a></h2> <p>We provide access to different subsets of the dataset and also created three different lower-dimensional projections that can be used. In particular, we computed two PCA projections using 32 and 96 dimensions and one more projection into binary sketches designed to work with bit-level hamming distance &#40;using 1024 bits&#41;. Find below the URLs to download these bundles. </p> <h2 id=768d_clip_embeddings_clip768 ><a href="#768d_clip_embeddings_clip768" class=header-anchor >768d clip embeddings &#40;clip768&#41;</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-clip768v2-n&#61;100M.h5">laion2B-en-clip768v2-n&#61;100M.h5</a><td align=right >100M subset<td align=right >147G<td align=right >9d8ee3347b1edf136b3ef38162ac05c3<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-clip768v2-n&#61;30M.h5">laion2B-en-clip768v2-n&#61;30M.h5</a><td align=right >30M subset<td align=right >44G<td align=right >15a24d28d2304e14711e23baf7fe86a4<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-clip768v2-n&#61;10M.h5">laion2B-en-clip768v2-n&#61;10M.h5</a><td align=right >10M subset<td align=right >15G<td align=right >c05e4b1d2b2a0c7663ac9767753e25e1<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-clip768v2-n&#61;300K.h5">laion2B-en-clip768v2-n&#61;300K.h5</a><td align=right >300K subset, for developing purposes<td align=right >440M<td align=right >d238b4b037c32bae41e497f95dffa895<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-clip768v2-n&#61;100K.h5">laion2B-en-clip768v2-n&#61;100K.h5</a><td align=right >100K subset, for developing purposes<td align=right >147M<td align=right >daef38a64e3cd1c5233231f8be882a64<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/public-queries-10k-clip768v2.h5">public-queries-10k-clip768v2.h5</a><td align=right >10k public query set &#40;original 768d embeddings&#41;<td align=right >30M<td align=right >257b9eb3f7f25776e0d33b22451b7b32<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/private-queries-10k-clip768v2.h5">private-queries-10k-clip768v2.h5</a><td align=right >10k private query set &#40;original 768d embeddings&#41;<td align=right >30M<td align=right >f8f3e61bd22d7d64234a0f587ead9fcf</table> <h2 id=32d_pca_projections_pca32 ><a href="#32d_pca_projections_pca32" class=header-anchor >32d PCA projections &#40;pca32&#41;</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-pca32v2-n&#61;100M.h5">laion2B-en-pca32v2-n&#61;100M.h5</a><td align=right >100M subset<td align=right >13G<td align=right >02c5726ba41cbfd3320d75ad113ef008<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-pca32v2-n&#61;30M.h5">laion2B-en-pca32v2-n&#61;30M.h5</a><td align=right >30M subset<td align=right >3.7G<td align=right >cf34551e4a80689a155052de640874b1<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-pca32v2-n&#61;10M.h5">laion2B-en-pca32v2-n&#61;10M.h5</a><td align=right >10M subset<td align=right >1.3G<td align=right >799dfd317976012a9b768aea123ce6b0<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-pca32v2-n&#61;300K.h5">laion2B-en-pca32v2-n&#61;300K.h5</a><td align=right >300K subset, for developing purposes<td align=right >37M<td align=right >aeffa3290eedd6063f138d5a81489128<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-pca32v2-n&#61;100K.h5">laion2B-en-pca32v2-n&#61;100K.h5</a><td align=right >100K subset, for developing purposes<td align=right >13M<td align=right >45a6c4e3774430d6318f808b43053895<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/public-queries-10k-pca32v2.h5">public-queries-10k-pca32v2.h5</a><td align=right >10k public query set for 32d PCA projection<td align=right >1.3M<td align=right >8c0fa4fff523d6263a246f7553d2b92f<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/private-queries-10k-pca32v2.h5">private-queries-10k-pca32v2.h5</a><td align=right >10k private query set for 32d PCA projection<td align=right >1.3M<td align=right >57dc078229325b6c161521512585738e</table> <h2 id=96d_pca_projections_pca96 ><a href="#96d_pca_projections_pca96" class=header-anchor >96d PCA projections &#40;pca96&#41;</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-pca96v2-n&#61;100M.h5">laion2B-en-pca96v2-n&#61;100M.h5</a><td align=right >100M subset<td align=right >37G<td align=right >715c1f5bfa3da61eaf5e2e8735052043<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-pca96v2-n&#61;30M.h5">laion2B-en-pca96v2-n&#61;30M.h5</a><td align=right >30M subset<td align=right >11G<td align=right >17b783ca3714b4b8084d93d59bac4611<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-pca96v2-n&#61;10M.h5">laion2B-en-pca96v2-n&#61;10M.h5</a><td align=right >10M subset<td align=right >3.7G<td align=right >4f2520b152929bcd34fb3912d4db025e<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-pca96v2-n&#61;300K.h5">laion2B-en-pca96v2-n&#61;300K.h5</a><td align=right >300K subset, for developing purposes<td align=right >110M<td align=right >97faba380163a5ec2e1a441c3a6d21b6<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-pca96v2-n&#61;100K.h5">laion2B-en-pca96v2-n&#61;100K.h5</a><td align=right >100K subset, for developing purposes<td align=right >37M<td align=right >73d464eccd6a6695d1f78f67bfbc7b46<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/public-queries-10k-pca96v2.h5">public-queries-10k-pca96v2.h5</a><td align=right >10k public query set for 96d PCA projection<td align=right >3.7M<td align=right >f7d0b77f336f8f63803ddb59b4d4b8ed<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/private-queries-10k-pca96v2.h5">private-queries-10k-pca96v2.h5</a><td align=right >10k private query set for 96d PCA projection<td align=right >3.7M<td align=right >301330e6d3963dd2db923fd4e858aa4e</table> <h2 id=1024-bit_binary_sketches_hamming ><a href="#1024-bit_binary_sketches_hamming" class=header-anchor >1024-bit binary sketches &#40;hamming&#41;</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-hammingv2-n&#61;100M.h5">laion2B-en-hammingv2-n&#61;100M.h5</a><td align=right >100M subset<td align=right >13G<td align=right >36030a46f0792d8c520b85a39ea64dfc<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-hammingv2-n&#61;30M.h5">laion2B-en-hammingv2-n&#61;30M.h5</a><td align=right >30M subset<td align=right >3.7G<td align=right >9f438fd469e21313684f191d375c63ed<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-hammingv2-n&#61;10M.h5">laion2B-en-hammingv2-n&#61;10M.h5</a><td align=right >10M subset<td align=right >1.3G<td align=right >13a28c054a351c2b2cdd8fd918b006ed<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-hammingv2-n&#61;300K.h5">laion2B-en-hammingv2-n&#61;300K.h5</a><td align=right >300K subset, for developing purposes<td align=right >37M<td align=right >03533c23fcc18c806cd42653e46fda89<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-hammingv2-n&#61;100K.h5">laion2B-en-hammingv2-n&#61;100K.h5</a><td align=right >100K subset, for developing purposes<td align=right >13M<td align=right >0dcb6fc72284439f67debcb34080b282<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/public-queries-10k-hammingv2.h5">public-queries-10k-hammingv2.h5</a><td align=right >10k public query set for 1024-bit binary sketch projection<td align=right >1.3M<td align=right >cd93f7bf61a436b5a45d0b3e1a002667<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/private-queries-10k-pca96v2.h5">private-queries-10k-pca96v2.h5</a><td align=right >10k private query set for 1024-bit binary sketch projection<td align=right >3.7M<td align=right >301330e6d3963dd2db923fd4e858aa4e</table> <h2 id=gold_standard_list_computed_with_32-bit_floating_point_arithmetic_100_nearest_neighbors ><a href="#gold_standard_list_computed_with_32-bit_floating_point_arithmetic_100_nearest_neighbors" class=header-anchor >Gold standard list &#40;computed with 32-bit floating point arithmetic, 100 nearest neighbors&#41;</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-100M.h5">laion2B-en-public-gold-standard-v2-100M.h5</a><td align=right >100M gold standard<td align=right >7.7M<td align=right >35de58992c6446c85c56e710b144c90c<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-30M.h5">laion2B-en-public-gold-standard-v2-30M.h5</a><td align=right >30M gold standard<td align=right >7.7M<td align=right >1726691372d2f62d7b0b97d8bf4f6189<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-10M.h5">laion2B-en-public-gold-standard-v2-10M.h5</a><td align=right >10M gold standard<td align=right >7.7M<td align=right >b68b17693253d95e1fc94c217af25e95<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-300K.h5">laion2B-en-public-gold-standard-v2-300K.h5</a><td align=right >300K gold standard<td align=right >7.7M<td align=right >258654f2a34a1bdbfa031862b4e6cfae<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-100K.h5">laion2B-en-public-gold-standard-v2-100K.h5</a><td align=right >100K gold standard<td align=right >7.7M<td align=right >fe39725772f487e4c86af68e18e87c88</table> <h2 id=gold_standard_for_public_queries_computed_with_64-bit_ieee_floating_point_arithmetic_1000_nearest_neighbors ><a href="#gold_standard_for_public_queries_computed_with_64-bit_ieee_floating_point_arithmetic_1000_nearest_neighbors" class=header-anchor >Gold standard for public queries &#40;computed with 64-bit IEEE floating point arithmetic, 1000 nearest neighbors&#41;</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-100M-F64-IEEE754.h5">laion2B-en-public-gold-standard-v2-100M-F64-IEEE754.h5</a><td align=right >100M gold standard<td align=right >77M<td align=right >59321e7e33b5469a5b435ff11305257f<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-30M-F64-IEEE754.h5">laion2B-en-public-gold-standard-v2-30M-F64-IEEE754.h5</a><td align=right >30M gold standard<td align=right >77M<td align=right >a445f32702aa43a176b56c54bf3f03f9<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-10M-F64-IEEE754.h5">laion2B-en-public-gold-standard-v2-10M-F64-IEEE754.h5</a><td align=right >10M gold standard<td align=right >77M<td align=right >45b05e4d60b8a66088b378ae7e0d278f<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-300K-F64-IEEE754.h5">laion2B-en-public-gold-standard-v2-300K-F64-IEEE754.h5</a><td align=right >300K gold standard<td align=right >77M<td align=right >5d635f26630cced971358fd76f37c32e</table> <h2 id=gold_standard_for_private_queries_computed_with_64-bit_ieee_floating_point_arithmetic_1000_nearest_neighbors ><a href="#gold_standard_for_private_queries_computed_with_64-bit_ieee_floating_point_arithmetic_1000_nearest_neighbors" class=header-anchor >Gold standard for private queries &#40;computed with 64-bit IEEE floating point arithmetic, 1000 nearest neighbors&#41;</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/laion2B-en-private-gold-standard-v2-10M-F64-IEEE754.h5">laion2B-en-private-gold-standard-v2-10M-F64-IEEE754.h5</a><td align=right >10M private gold standard<td align=right >783K<td align=right >f384beecb5dddcddca8efc00a7fcd911<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/laion2B-en-private-gold-standard-v2-30M-F64-IEEE754.h5">laion2B-en-private-gold-standard-v2-30M-F64-IEEE754.h5</a><td align=right >30M private gold standard<td align=right >783K<td align=right >3b43d7b1251bd1387419a245bec8ba55<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/laion2B-en-private-gold-standard-v2-100M-F64-IEEE754.h5">laion2B-en-private-gold-standard-v2-100M-F64-IEEE754.h5</a><td align=right >100M private gold standard<td align=right >783K<td align=right >0ab272fd7b0eee8beec378e67da85b65</table> <p>For instance, you can download the 10M subset and the query set using the following commands from a typical linux terminal:</p> <pre><code class="bash hljs">curl -O https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-clip768v2-n=10M.h5
curl -O https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/public-queries-10k-clip768v2.h5</code></pre> <p>Note that our projection models were trained with our 10M subset. Other approaches may vary the resulting quality.</p> <p><strong>Note</strong>: Projections will reduce the result&#39;s quality concerning the original embeddings, but you can use these datasets to fast prototype your solution and for hyperparameter optimization. Please email us if you are interested in the associated metadata &#40;which can also be obtained as described in the rest of the document.&#41;</p> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> sisap challenge committee. Last modified: March 12, 2025. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> <script src="/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script>