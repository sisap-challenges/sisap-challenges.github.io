<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/poole_hyde.css"> <link rel=stylesheet  href="/css/sisap.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/assets/favicon.png"> <title>LAION2B Dataset</title> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <img alt="sisap logo" src="https://www.sisap.org/2023/images/sisap.png" /> <h1><a href="/">SISAP Indexing challenge</a></h1> <p class=lead >challenge</p> </div> <nav class=sidebar-nav > <a class="sidebar-nav-item " href="/">Home</a> <a class="sidebar-nav-item " href="/2024/tasks/">Tasks</a> <a class="sidebar-nav-item " href="/2024/evaluationmethodology/">Methodology</a> <a class="sidebar-nav-item active" href="/2024/datasets/">Datasets</a> <a class="sidebar-nav-item " href="/2024/repoexamples/">Repository examples</a> <a class="sidebar-nav-item " href="/2024/committee/">Committee and pre-registration</a> <a class="sidebar-nav-item " href="/ioformats/">Inputs and outputs</a> <a class="sidebar-nav-item " href="/2023/">2023 edition</a> </nav> <p>&copy; sisap challenge committee.</p> </div> </div> <div class="content container"> <div class=franklin-content > <h1 id=the_laion2b_and_projections ><a href="#the_laion2b_and_projections" class=header-anchor >The LAION2B and projections</a></h1> <div class=franklin-toc ><ol><li><a href="#about_the_laion5b">About the LAION5B</a><ol><li><a href="#some_notes_about_the_data">Some notes about the data</a></ol><li><a href="#data">Data</a><li><a href="#768d_clip_embeddings_clip768">768d clip embeddings &#40;clip768&#41;</a><li><a href="#gold_standard_for_private_queries_computed_with_64-bit_ieee_floating_point_arithmetic_1000_nearest_neighbors">Gold standard for private queries &#40;computed with 64-bit IEEE floating point arithmetic, 1000 nearest neighbors&#41;</a></ol></div> <h2 id=about_the_laion5b ><a href="#about_the_laion5b" class=header-anchor >About the LAION5B</a></h2> <p>The <strong>LAION5B</strong> dataset is an openly available image collection that has been used for learning very large visual and language deep-neural models; for instance, the famed stable diffusion generative model used it as the training set.</p> <p>A more detailed description can be found here:</p> <div class=important ><em>Schuhmann, C., Beaumont, R., Vencu, R., Gordon, C., Wightman, R., Cherti, M., ... &amp; Jitsev, J. &#40;2022&#41;. Laion-5b: An open large-scale dataset for training next generation image-text models. arXiv preprint arXiv:2210.08402.</em></div> <p>The challenge use a 100M subset of the English subset, often called LAION2B, our objects are not marked as NFSW. We use 768-dimensional vector embeddings.</p> <h3 id=some_notes_about_the_data ><a href="#some_notes_about_the_data" class=header-anchor >Some notes about the data</a></h3> <ul> <li><p>You will get 768 dimensional 16-bit floating point vectors that may be changed to a 32-bit format to get full speed on legacy hardware.</p> <li><p>Our gold-standards were computed using dot product as similarity; vectors are almost <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8333em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>-normalized, so you can use the cosine distance or the angle distance as well to get a good aproximation.</p> <li><p>Our gold-standard <code>.h5</code> files contain the 1000 nearest neighbors of each query using two associated matrices <code>knns</code> and <code>dists</code>, i.e., columns correspond to queries and rows to nearest neighbors for each query.</p> <ul> <li><p>The <code>knns</code> identifiers start indexing on 1.</p> <li><p>The <code>dists</code> contains raw similarity values for each corresponding query and object; please consider that this is not a proper metric distance. People using metric properties can use the angle with minor changes. We will not check distance values for the final ranking. </p> </ul> </ul> <h2 id=data ><a href="#data" class=header-anchor >Data</a></h2> <h2 id=768d_clip_embeddings_clip768 ><a href="#768d_clip_embeddings_clip768" class=header-anchor >768d clip embeddings &#40;clip768&#41;</a></h2></p> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-clip768v2-n&#61;100M.h5">laion2B-en-clip768v2-n&#61;100M.h5</a><td align=right >100M subset<td align=right >147G<td align=right >9d8ee3347b1edf136b3ef38162ac05c3<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-clip768v2-n&#61;300K.h5">laion2B-en-clip768v2-n&#61;300K.h5</a><td align=right >300K subset, for developing purposes<td align=right >440M<td align=right >d238b4b037c32bae41e497f95dffa895<tr><td align=right ><a href="http://ingeotec.mx/~sadit/SISAP23-Challenge/private-queries-10k-clip768v2.h5">private-queries-10k-clip768v2.h5</a><td align=right >10k private query set &#40;original 768d embeddings&#41;<td align=right >30M<td align=right >f8f3e61bd22d7d64234a0f587ead9fcf</table> <h2 id=gold_standard_for_private_queries_computed_with_64-bit_ieee_floating_point_arithmetic_1000_nearest_neighbors ><a href="#gold_standard_for_private_queries_computed_with_64-bit_ieee_floating_point_arithmetic_1000_nearest_neighbors" class=header-anchor >Gold standard for private queries &#40;computed with 64-bit IEEE floating point arithmetic, 1000 nearest neighbors&#41;</a></h2> <p>| dataset | description | size | md5 | |––––-|––––––-|–––|–––––| <p>For instance, you can download the 10M subset and the query set using the following commands from a typical linux terminal:</p> <pre><code class="bash hljs">curl -O https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/laion2B-en-clip768v2-n=10M.h5
curl -O https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/public-queries-10k-clip768v2.h5</code></pre> <p>Note that our projection models were trained with our 10M subset. Other approaches may vary the resulting quality.</p> <p><strong>Note</strong>: Projections will reduce the result&#39;s quality concerning the original embeddings, but you can use these datasets to fast prototype your solution and for hyperparameter optimization. Please email us if you are interested in the associated metadata &#40;which can also be obtained as described in the rest of the document.&#41;</p> <div class=warn >The original dataset can be downloaded and processed to get different subsets as described in <a href="/downloading-laion/">the downloading and preprocessing LAION</a> page. We encourage challenge participants to use the provided bundles for consistency reasons.</div> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> sisap challenge committee. Last modified: March 14, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> <script src="/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script>