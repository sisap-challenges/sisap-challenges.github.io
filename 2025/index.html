<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/poole_hyde.css"> <link rel=stylesheet  href="/css/sisap.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/assets/favicon.png"> <title>Task description and call for participation SISAP 2025 Indexing Challenge</title> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <img alt="sisap logo" src="https://www.sisap.org/2023/images/sisap.png" /> <h1><a href="/">SISAP Indexing challenge</a></h1> <p class=lead >challenge</p> </div> <nav class=sidebar-nav > <a class="sidebar-nav-item " href="/">Home</a> <!--a class="sidebar-nav-item {{ispage 2025/evaluationmethodology/*}}active{{end}}" href="/2025/evaluationmethodology/">Methodology</a> <a class="sidebar-nav-item {{ispage 2025/datasets/*}}active{{end}}" href="/2025/datasets/">Datasets</a> <a class="sidebar-nav-item {{ispage 2025/repoexamples/*}}active{{end}}" href="/2025/repoexamples/">Repository examples</a> --> <!--a class="sidebar-nav-item {{ispage ioformats/*}}active{{end}}" href="/ioformats/">Inputs and outputs</a--> <a class="sidebar-nav-item " href="/2024/">2024 edition</a> <a class="sidebar-nav-item " href="/2023/">2023 edition</a> </nav> <p>&copy; sisap challenge committee.</p> </div> </div> <div class="content container"> <div class=franklin-content ><p> </p> <h1 id=task_description_and_call_for_participation_sisap_2025_indexing_challenge ><a href="#task_description_and_call_for_participation_sisap_2025_indexing_challenge" class=header-anchor >Task description and call for participation SISAP 2025 Indexing Challenge</a></h1> <div class=franklin-toc ><ol><li><a href="#introduction">Introduction</a><li><a href="#task_1_resource-limited_indexing">Task 1: Resource-limited indexing</a><li><a href="#task_2_k-nearest_neighbor_graph_aka_metric_self-join">Task 2: K-nearest neighbor graph &#40;a.k.a. metric self-join&#41;</a><li><a href="#test_data_and_queries">Test Data and Queries</a><ol><li><a href="#hardware_specifications">Hardware specifications</a></ol><li><a href="#registration_and_participation">Registration and participation</a><ol><li><a href="#paper_submissions">Paper submissions</a><li><a href="#final_comments">Final comments</a></ol><li><a href="#examples">Examples</a><li><a href="#important_dates">Important Dates</a><li><a href="#sisap_indexing_challenge_chairs">SISAP Indexing Challenge Chairs</a><li><a href="#frequently_asked_questions_faq">Frequently Asked Questions &#40;FAQ&#41;</a></ol></div> <h2 id=introduction ><a href="#introduction" class=header-anchor >Introduction</a></h2> <p>The SISAP Indexing Challenge 2025 invites researchers and practitioners to participate in exciting tasks to advance the state of the art in similarity search and indexing. The challenge provides a platform for presenting innovative solutions and pushing the boundaries of efficiency and effectiveness in large-scale similarity search indexes. This year, we are opening two challenging tasks.</p> <p>Datasets can be found in <a href="https://huggingface.co/datasets/sadit/SISAP2025/tree/main">https://huggingface.co/datasets/sadit/SISAP2025/tree/main</a>; you can clone the full repository or download each file.</p> <h2 id=task_1_resource-limited_indexing ><a href="#task_1_resource-limited_indexing" class=header-anchor >Task 1: Resource-limited indexing</a></h2> <p>This task challenges participants to develop memory-efficient indexing solutions with reranking capabilities. Each solution will be run in a Linux container with limited memory and storage resources.</p> <ul> <li><p>Container specifications: 8 virtual CPUs, 16 GB of RAM, the dataset will be mounted read-only into the container. </p> <li><p>Wall clock time for the entire task: 12 hours. </p> <li><p>Minimum average recall to be considered in the final ranking: 0.7. </p> <li><p>Dataset: PUBMED23 &#40;23 million vectors &#40;384 dimensions&#41; with <em>out-of-distribution</em> queries&#41;. </p> <li><p>The goal is to evaluate k&#61;30 nearest neighbors for a large set of query objects, as follows: </p> <ul> <li><p>The final score of each team is measured as the best throughput evaluated on up to 16 different search hyperparameters. </p> <li><p>Teams are provided with a public set of 11,000 query objects for development purposes. </p> <li><p>A private set of 10,000 new queries will be used for the final evaluation. </p> </ul> </ul> <h2 id=task_2_k-nearest_neighbor_graph_aka_metric_self-join ><a href="#task_2_k-nearest_neighbor_graph_aka_metric_self-join" class=header-anchor >Task 2: K-nearest neighbor graph &#40;a.k.a. metric self-join&#41;</a></h2> <p>In this task, participants are asked to develop memory-efficient indexing solutions that will be used to compute an approximation of the <em>k-</em>nearest neighbor graph for <em>k&#61;15</em>. Each solution will be run in a Linux container with limited memory and storage resources.</p> <ul> <li><p>Container specifications: 8 virtual CPUs, 16 GB of RAM, the dataset will be mounted read-only into the container. </p> <li><p>Wall clock time for the entire task: 12 hours. </p> <li><p>Minimum average recall to be considered in the final ranking: 0.8. </p> <li><p>Dataset: GOOAQ &#40;3 million vectors &#40;384 dimensions&#41; &#41;. </p> <li><p>The goal is to compute the <em>k-nearest neighbor graph &#40;without self-references&#41;</em>, i.e., find the <em>k</em>-nearest neighbors using all objects in the dataset as queries. </p> <ul> <li><p>We will measure graph’s quality as the recall against a provided gold standard and the full computation time &#40;i.e., including preprocessing, indexing, and search, and postprocessing&#41; </p> <li><p>We provide a development dataset; the evaluation phase will use an undisclosed dataset of similar size computed with the same neural model.</p> </ul> </ul> <h2 id=test_data_and_queries ><a href="#test_data_and_queries" class=header-anchor >Test Data and Queries</a></h2> <ul> <li><p>The h5 file structure is described in <a href="https://huggingface.co/datasets/sadit/SISAP2025">https://huggingface.co/datasets/sadit/SISAP2025</a>. </p> <li><p>Each file contains vector embeddings computed in Sentence-BERT models over text datasets; for Task 1 we provide <em>in-distribution</em> queries and <em>out-of-distribution</em> queries for each dataset, so you can develop and compare your methods with different datasets. </p> <li><p>Similarity between two objects is measured by their dot product. </p> <li><p>Gold standards are given as a matrix of object identifiers &#40;indexing starts at 1&#41;. </p> <li><p>Task 2 gold standards contain self-references that will be removed before recall computation.</p> </ul> <h3 id=hardware_specifications ><a href="#hardware_specifications" class=header-anchor >Hardware specifications</a></h3> <p>The evaluation will be carried out on a machine with the following specifications:</p> <ul> <li><p>2x Intel&#40;R&#41; Xeon&#40;R&#41; CPU E5-2690 v4 @ 2.60GHz, 28 cores in total </p> <li><p>512 GB RAM &#40;DDR4, 2400 MT/s&#41; </p> <li><p>1 TB SSD </p> </ul> <h2 id=registration_and_participation ><a href="#registration_and_participation" class=header-anchor >Registration and participation</a></h2> <ol> <li><p>Register for the challenge by opening a <em>&quot;Pre-registration request&quot;</em> issue in the GitHub repository <a href="https://github.com/sisap-challenges/challenge2025/">https://github.com/sisap-challenges/challenge2025/</a>. Fill out the required data, taking into account that the given data will be used to keep in contact while the challenge remains open. </p> <li><p>During the development phase, participants will have access to a gold-standard corresponding to that phase. </p> <li><p>Teams are required to provide public GitHub repositories with working GitHub Actions and clear instructions on how to run their solutions with the correct hyperparameters &#40;up to 16 sets&#41; for each task. You can use a small dataset like the given CCNEWS. Submissions are required to run in docker containers. See below for examples.</p> <li><p>Participants&#39; repositories will be cloned and tested at the time of the challenge. Results will be shared with the authors for verification and potential fixes before the final rankings are published. </p> <li><p>The evaluation queryset for Task 1 and the evaluation dataset for Task 2 will be disclosed after the evaluation phase.</p> </ol> <h3 id=paper_submissions ><a href="#paper_submissions" class=header-anchor >Paper submissions</a></h3> <p>All participants will be considered for paper submissions. We aim to accommodate all accepted papers within the conference program. Papers should be short, focusing on the presentation and poster.</p> <p>We look forward to your participation and innovative solutions in the SISAP Indexing Challenge 2025&#33; Let&#39;s push the frontiers of similarity search and indexing together.</p> <h3 id=final_comments ><a href="#final_comments" class=header-anchor >Final comments</a></h3> <p>Any transformation of the dataset to load, index, and solve nearest neighbor queries is allowed. Transformations include but are not limited to, packing into different data types, dimensional reduction, locality-sensitive hashing, product quantization, or transforming into binary sketches. Reproducibility and open science are primary goals of the challenge, so we accept only public GitHub repositories with working GitHub Actions as submissions. Indexing algorithms may be already published or original contributions.</p> <p>You can find more detailed information, data access, and registration at the SISAP Indexing Challenge website <a href="https://sisap-challenges.github.io/2025/">https://sisap-challenges.github.io/2025/</a></p> <h2 id=examples ><a href="#examples" class=header-anchor >Examples</a></h2> <ul> <li><p>Julia example – <a href="https://github.com/sisap-challenges/sisap25-example-julia">https://github.com/sisap-challenges/sisap25-example-julia</a></p> <ul> <li><p>Working examples for Task 1 and Task 2.</p> <li><p>GitHub Actions &#40;check the <a href="https://github.com/sisap-challenges/sisap25-example-julia/actions/runs/13662636806">artifacts</a> for a brief report&#41;.</p> <li><p>Dockerfile will be finished soon.</p> </ul> <li><p>Python example – <a href="https://github.com/sisap-challenges/sisap25-example-python">https://github.com/sisap-challenges/sisap25-example-python</a></p> <ul> <li><p>Working examples for Task 1 and Task 2.</p> <li><p>GitHub Actions &#40;check the <a href="https://github.com/sisap-challenges/sisap25-example-python/actions/runs/13922634862">artifacts</a> for a brief report&#41;.</p> <li><p>Dockerfile will be finished soon.</p> </ul> </ul> <h2 id=important_dates ><a href="#important_dates" class=header-anchor >Important Dates</a></h2> <ul> <li><p>June 6th. Submission of solution implementations deadline. </p> <li><p>June 13th. Short paper descriptions deadline. </p> <li><p>July 1st. Final ranking announcement. </p> <li><p>July 11th. Paper notification. </p> <li><p>July 31st. Participant &#40;short paper&#41; camera ready.</p> </ul> <h2 id=sisap_indexing_challenge_chairs ><a href="#sisap_indexing_challenge_chairs" class=header-anchor >SISAP Indexing Challenge Chairs</a></h2> <ul> <li><p>Edgar L. Chavez, CICESE, México &lt;elchavez@cicese.edu.mx&gt; </p> <li><p>Eric S. Téllez, INFOTEC-SECIHTI, México &lt;eric.tellez@ieee.org&gt; </p> <li><p>Martin Aumüller, ITU Copenhagen, Denmark &lt;maau@itu.dk&gt; </p> <li><p>Vladimir Mic, Aarhus University, Denmark &lt;v.mic@cs.au.dk&gt;</p> </ul> <h2 id=frequently_asked_questions_faq ><a href="#frequently_asked_questions_faq" class=header-anchor >Frequently Asked Questions &#40;FAQ&#41;</a></h2> <ol> <li><p><strong>What does the 12-hour time limit include?</strong></p> </ol> <ul> <li><p>Twelve hours is the wall clock for the evaluation process; i.e., we will <em>stop</em> the container after these 12 hours.</p> <li><p>Preparations based on space characteristics &#40;training models, pivot selection, etc.&#41; are not involved in the time limit but must be previously trained and distributed as part of the solution.</p> <li><p>Preparations that treat each data item from the searched dataset, for example by reducing a vector&#39;s dimensionality or hashing of data items, are meant to be made in the running container. The evaluation will be carried out on a random permutation of the dataset.</p> </ul> <ol start=2 > <li><p><strong>Do I need to write the necessary code to fetch datasets?</strong></p> </ol> <ul> <li><p>At evaluation time we will have evaluation dataset and queries in a local directory, so you do not need to retrieve them.</p> <li><p>Use the same filenames that we use in the provided examples.</p> </ul> <ol start=3 > <li><p><strong>Can I use a network service to solve the indexing challenge?</strong></p> </ol> <ul> <li><p>No. We will not isolate the evaluation container from the network, but we will use a unknown permutation of the dataset.</p> </ul> <ol start=4 > <li><p><strong>What do you mean by recall?</strong></p> </ol> <ul> <li><p>The proportion of exact <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>-NN results among the top-<span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> nearest neighbors of your solution &#40;Task 1 uses <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>30</mn></mrow><annotation encoding="application/x-tex">k=30</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >30</span></span></span></span>, Task 2 uses <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>15</mn></mrow><annotation encoding="application/x-tex">k=15</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >15</span></span></span></span>&#41;.</p> <li><p>We precomputed a gold standard &#40;groundtruth&#41;; we will check against identifiers, not distance values.</p> <li><p>Identifiers in the gold standard start at 1, not 0.</p> <li><p>See the evaluation code for examples of how the recall is computed.</p> </ul> <ol start=5 > <li><p><strong>What can be placed on the secondary memory? &#40;SSD technology&#41;</strong></p> </ol> <ul> <li><p>You can use the SSD to store whatever you need for running your solution, but its size is limited to the size of each dataset given by the size of its <code>.h5</code> file.</p> <li><p>We will remove everything after running your solution. </p> </ul> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> sisap challenge committee. Last modified: March 20, 2025. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div>