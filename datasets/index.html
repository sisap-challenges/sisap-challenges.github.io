<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/poole_hyde.css"> <link rel=stylesheet  href="/css/sisap.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="/assets/favicon.png"> <title>LAION2B Dataset</title> <div class=sidebar > <div class="container sidebar-sticky"> <div class=sidebar-about > <img alt="sisap logo" src="https://www.sisap.org/2023/images/sisap.png" /> <h1><a href="/">SISAP 2023</a></h1> <p class=lead >LAION2B challenge</p> </div> <nav class=sidebar-nav > <a class="sidebar-nav-item " href="/">Home</a> <a class="sidebar-nav-item " href="/tasks/">Tasks</a> <a class="sidebar-nav-item " href="/evaluationmethodology/">Methodology</a> <a class="sidebar-nav-item active" href="/datasets/">Datasets</a> <a class="sidebar-nav-item " href="/ioformats/">Inputs and outputs</a> <a class="sidebar-nav-item " href="/repoexamples/">Repository examples</a> <a class="sidebar-nav-item " href="/committee">Committee and pre-registration</a> </nav> <p>&copy; sisap challenge committee.</p> </div> </div> <div class="content container"> <div class=franklin-content > <h1 id=the_laion2b_and_projections ><a href="#the_laion2b_and_projections" class=header-anchor >The LAION2B and projections</a></h1> <div class=franklin-toc ><ol><li><a href="#about_the_laion5b">About the LAION5B</a><ol><li><a href="#subset_of_the_challenge">Subset of the challenge</a></ol><li><a href="#subsets">Subsets</a><li><a href="#768d_clip_embeddings_clip768">768d clip embeddings &#40;clip768&#41;</a><li><a href="#32d_pca_projections_pca32">32d PCA projections &#40;pca32&#41;</a><li><a href="#96d_pca_projections_pca96">96d PCA projections &#40;pca96&#41;</a><li><a href="#1024-bit_binary_sketches_hamming">1024-bit binary sketches &#40;hamming&#41;</a><li><a href="#gold_standard_list">Gold standard list</a><ol><li><a href="#metadata">Metadata</a></ol><li><a href="#downloading_the_dataset">Downloading the dataset</a><ol><li><a href="#filtering_out_nsfw_to_get_the_precise_subsets">Filtering out NSFW to get the precise subsets</a></ol></ol></div> <h2 id=about_the_laion5b ><a href="#about_the_laion5b" class=header-anchor >About the LAION5B</a></h2> <p>The <strong>LAION5B</strong> dataset is an openly available image collection that has been used for learning very large visual and language deep-neural models; for instance, the famed stable diffusion generative model used it as the training set. The collection equips each image with a URL handle, allowing people to showcase demonstrations easily.</p> <p>A more detailed description can be found here:</p> <div class=important ><em>Schuhmann, C., Beaumont, R., Vencu, R., Gordon, C., Wightman, R., Cherti, M., ... &amp; Jitsev, J. &#40;2022&#41;. Laion-5b: An open large-scale dataset for training next generation image-text models. arXiv preprint arXiv:2210.08402.</em></div> <p>The English subset, often called LAION2B, contains over 2 billion objects.</p> <h3 id=subset_of_the_challenge ><a href="#subset_of_the_challenge" class=header-anchor >Subset of the challenge</a></h3> <p>The dataset is divided into parts containing close to 1M vectors. We selected the first 112 parts &#40;0000 to 0111&#41;; we used the first part to extract the public query set and the rest to extract the database. The subset use approximately 160GB of space and its associated metadata 20GB &#40;the first 112 parts&#41;. Embeddings are distributed using single precision &#40;16bits&#41; floating point vectors bundled in the NumPy data-specific format <code>.npz</code>. They can be loaded on most platforms due to the format&#39;s popularity.</p> <p>The challenge has three subsets:</p> <ul> <li><p>10M subset: concatenation of 1-11 parts.</p> <li><p>30M subset: concatenation of 1-33 parts.</p> <li><p>100M subset: concatenation of 1-111 parts.</p> <li><p>public queries: computed from part 0.</p> </ul> <p>All parts should be concatenated in order and also removing NSFW entries &#40;marked in metadata files&#41;.</p> <h2 id=subsets ><a href="#subsets" class=header-anchor >Subsets</a></h2> <p>We provide access to different subsets of the dataset and also created three different lower-dimensional projections that can be used. In particular, we computed two PCA projections using 32 and 96 dimensions and one more projection into binary sketches designed to work with bit-level hamming distance &#40;using 1024 bits&#41;. Find below the URLs to download these bundles. </p> <h2 id=768d_clip_embeddings_clip768 ><a href="#768d_clip_embeddings_clip768" class=header-anchor >768d clip embeddings &#40;clip768&#41;</a></h2></p> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/clip768/en-bundles/laion2B-en-clip768-n&#61;100M.h5">laion2B-en-clip768-n&#61;100M.h5</a><td align=right >100K subset<td align=right >147G<td align=right >9d8ee3347b1edf136b3ef38162ac05c3<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/clip768/en-bundles/laion2B-en-clip768-n&#61;30M.h5">laion2B-en-clip768-n&#61;30M.h5</a><td align=right >100K subset<td align=right >44G<td align=right >15a24d28d2304e14711e23baf7fe86a4<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/clip768/en-bundles/laion2B-en-clip768-n&#61;10M.h5">laion2B-en-clip768-n&#61;10M.h5</a><td align=right >100K subset<td align=right >15G<td align=right >c05e4b1d2b2a0c7663ac9767753e25e1<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/clip768/en-bundles/laion2B-en-clip768-n&#61;300K.h5">laion2B-en-clip768-n&#61;300K.h5</a><td align=right >100K subset, for developing purposes<td align=right >440M<td align=right >d238b4b037c32bae41e497f95dffa895<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/clip768/en-bundles/laion2B-en-clip768-n&#61;100K.h5">laion2B-en-clip768-n&#61;100K.h5</a><td align=right >100K subset, for developing purposes<td align=right >147M<td align=right >daef38a64e3cd1c5233231f8be882a64<tr><td align=right ><a href="https://sisap-23-challenge.s3.amazonaws.com/SISAP23-Challenge/clip768/en-queries/public-queries-10k-clip768.h5">public-queries-10k-clip768.h5</a><td align=right >10k public query set &#40;original 768d embeddings&#41;<td align=right >30M<td align=right >257b9eb3f7f25776e0d33b22451b7b32</table> <h2 id=32d_pca_projections_pca32 ><a href="#32d_pca_projections_pca32" class=header-anchor >32d PCA projections &#40;pca32&#41;</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-pca32v2-n&#61;100M.h5">laion2B-en-pca32v2-n&#61;100M.h5</a><td align=right >100M subset<td align=right >13G<td align=right >02c5726ba41cbfd3320d75ad113ef008<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-pca32v2-n&#61;30M.h5">laion2B-en-pca32v2-n&#61;30M.h5</a><td align=right >30M subset<td align=right >3.7G<td align=right >cf34551e4a80689a155052de640874b1<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-pca32v2-n&#61;10M.h5">laion2B-en-pca32v2-n&#61;10M.h5</a><td align=right >10M subset<td align=right >1.3G<td align=right >799dfd317976012a9b768aea123ce6b0<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-pca32v2-n&#61;300K.h5">laion2B-en-pca32v2-n&#61;300K.h5</a><td align=right >300K subset, for developing purposes<td align=right >37M<td align=right >aeffa3290eedd6063f138d5a81489128<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-pca32v2-n&#61;100K.h5">laion2B-en-pca32v2-n&#61;100K.h5</a><td align=right >100K subset, for developing purposes<td align=right >13M<td align=right >45a6c4e3774430d6318f808b43053895<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/public-queries-10k-pca32v2.h5">public-queries-10k-pca32v2.h5</a><td align=right >10k public query set for 32d PCA projection<td align=right >1.3M<td align=right >8c0fa4fff523d6263a246f7553d2b92f</table> <h2 id=96d_pca_projections_pca96 ><a href="#96d_pca_projections_pca96" class=header-anchor >96d PCA projections &#40;pca96&#41;</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-pca96v2-n&#61;100M.h5">laion2B-en-pca96v2-n&#61;100M.h5</a><td align=right >100M subset<td align=right >37G<td align=right >715c1f5bfa3da61eaf5e2e8735052043<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-pca96v2-n&#61;30M.h5">laion2B-en-pca96v2-n&#61;30M.h5</a><td align=right >30M subset<td align=right >11G<td align=right >17b783ca3714b4b8084d93d59bac4611<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-pca96v2-n&#61;10M.h5">laion2B-en-pca96v2-n&#61;10M.h5</a><td align=right >10M subset<td align=right >3.7G<td align=right >4f2520b152929bcd34fb3912d4db025e<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-pca96v2-n&#61;300K.h5">laion2B-en-pca96v2-n&#61;300K.h5</a><td align=right >300K subset, for developing purposes<td align=right >110M<td align=right >97faba380163a5ec2e1a441c3a6d21b6<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-pca96v2-n&#61;100K.h5">laion2B-en-pca96v2-n&#61;100K.h5</a><td align=right >100K subset, for developing purposes<td align=right >37M<td align=right >73d464eccd6a6695d1f78f67bfbc7b46<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/public-queries-10k-pca96v2.h5">public-queries-10k-pca96v2.h5</a><td align=right >10k public query set for 96d PCA projection<td align=right >3.7M<td align=right >f7d0b77f336f8f63803ddb59b4d4b8ed</table> <h2 id=1024-bit_binary_sketches_hamming ><a href="#1024-bit_binary_sketches_hamming" class=header-anchor >1024-bit binary sketches &#40;hamming&#41;</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-hammingv2-n&#61;100M.h5">laion2B-en-hammingv2-n&#61;100M.h5</a><td align=right >100M subset<td align=right >13G<td align=right >36030a46f0792d8c520b85a39ea64dfc<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-hammingv2-n&#61;30M.h5">laion2B-en-hammingv2-n&#61;30M.h5</a><td align=right >30M subset<td align=right >3.7G<td align=right >9f438fd469e21313684f191d375c63ed<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-hammingv2-n&#61;10M.h5">laion2B-en-hammingv2-n&#61;10M.h5</a><td align=right >10M subset<td align=right >1.3G<td align=right >13a28c054a351c2b2cdd8fd918b006ed<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-hammingv2-n&#61;300K.h5">laion2B-en-hammingv2-n&#61;300K.h5</a><td align=right >300K subset, for developing purposes<td align=right >37M<td align=right >03533c23fcc18c806cd42653e46fda89<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-hammingv2-n&#61;100K.h5">laion2B-en-hammingv2-n&#61;100K.h5</a><td align=right >100K subset, for developing purposes<td align=right >13M<td align=right >0dcb6fc72284439f67debcb34080b282<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/public-queries-10k-hammingv2.h5">public-queries-10k-hammingv2.h5</a><td align=right >10k public query set for 1024-bit binary sketch projection<td align=right >1.3M<td align=right >cd93f7bf61a436b5a45d0b3e1a002667</table> <h2 id=gold_standard_list ><a href="#gold_standard_list" class=header-anchor >Gold standard list</a></h2> <table><tr><th align=right >dataset<th align=right >description<th align=right >size<th align=right >md5<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-100M.h5">laion2B-en-public-gold-standard-v2-100M.h5</a><td align=right >100M gold standard<td align=right >7.7M<td align=right >35de58992c6446c85c56e710b144c90c<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-30M.h5">laion2B-en-public-gold-standard-v2-30M.h5</a><td align=right >30M gold standard<td align=right >7.7M<td align=right >1726691372d2f62d7b0b97d8bf4f6189<tr><td align=right ><a href="http://ingeotec.mx/~sadit/metric-datasets/LAION/SISAP23-Challenge/laion2B-en-public-gold-standard-v2-10M.h5">laion2B-en-public-gold-standard-v2-10M.h5</a><td align=right >10M gold standard<td align=right >7.7M<td align=right >b68b17693253d95e1fc94c217af25e95</table> <p>KeyError: key &quot;small-laion2B-en-public-gold-standard-v2-300K.h5&quot; not found <p>Note that our projection models were trained with the 2d part of the LAION2B dataset &#40;i.e, id&#61;0001 with approx. 1M vectors&#41;. Other approaches may vary the resulting quality.</p> <p><strong>Note</strong>: Projections will reduce the result&#39;s quality concerning the original embeddings, but you can use these datasets to fast prototype your solution and for hyperparameter optimization. Please email us if you are interested in the associated metadata &#40;which can also be obtained as described in the rest of the document.&#41;</p> <h1 id=original_laion_parts ><a href="#original_laion_parts" class=header-anchor >Original LAION parts</a></h1> <p>The LAION dataset is distributed in pairs of metadata and embeddings, bundled in parts of nearly 1 million each. Please note that the dataset contains many NSFW materials that must be discarded for our challenge, and this is made with the metadata information.</p> <h3 id=metadata ><a href="#metadata" class=header-anchor >Metadata</a></h3> <p>The metadata is publicly available through the <a href="https://laion.ai/blog/laion-5b/">LAION-5B</a> effort and the <a href="https://huggingface.co/laion">Hugging face repository</a>. </p> <h2 id=downloading_the_dataset ><a href="#downloading_the_dataset" class=header-anchor >Downloading the dataset</a></h2> <p>The embeddings are publicly available from the original mirror site <a href="https://mystic.the-eye.eu/public/AI/cah/laion5b/embeddings/">https://mystic.the-eye.eu/public/AI/cah/laion5b/embeddings/</a>.</p> <p>For instance, you can retrieve the first two parts &#40;and its associated meta data&#41; using a typical Linux installation using the terminal, as follows:</p> <pre><code class="bash hljs"><span class=hljs-built_in >mkdir</span> laion2B-en
<span class=hljs-built_in >cd</span> laion2B-en

curl -O https://mystic.the-eye.eu/public/AI/cah/laion5b/embeddings/laion2B-en/img_emb/img_emb_0000.npy
curl -O https://mystic.the-eye.eu/public/AI/cah/laion5b/embeddings/laion2B-en/laion2B-en-metadata/metadata_0000.parquet
curl -O https://mystic.the-eye.eu/public/AI/cah/laion5b/embeddings/laion2B-en/img_emb/img_emb_0001.npy
curl -O https://mystic.the-eye.eu/public/AI/cah/laion5b/embeddings/laion2B-en/laion2B-en-metadata/metadata_0001.parquet</code></pre> <p>You can download all parts using the following bash script</p> <pre><code class="bash hljs"><span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> {0000..1111}; <span class=hljs-keyword >do</span>
    <span class=hljs-built_in >echo</span> curl -O https://mystic.the-eye.eu/public/AI/cah/laion5b/embeddings/laion2B-en/img_emb/img_emb_<span class=hljs-variable >$i</span>.npy
<span class=hljs-keyword >done</span></code></pre> <p>Remove the <code>echo</code> command to actually start downloading.</p> <p>Troubleshooting: You can restart and resume partial downloads adding <code>-C -</code> to the <code>curl</code> command line, as follows:</p> <pre><code class="bash hljs">curl -C - -O https://mystic.the-eye.eu/public/AI/cah/laion5b/embeddings/laion2B-en/img_emb/img_emb_0000.npy</code></pre>
<h3 id=filtering_out_nsfw_to_get_the_precise_subsets ><a href="#filtering_out_nsfw_to_get_the_precise_subsets" class=header-anchor >Filtering out NSFW to get the precise subsets</a></h3>
<p>Each dataset part has metadata and embedding files. The metadata file is an Apache parquet table where we can find registers containing information like URL, description, and NSFW status, among other fields. Participants must use the NSFW field to obtain a mask for <em>NSFW</em> that should be used to get the desired sub-matrix. </p>
<p>The following script for the Julia language can be used for this purpose. Once you have downloaded the LAION parts and metadata, run the Julia REPL in the directory where you saved the files. The necessary packages will be asked to be installed:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> Parquet2, DataFrames, Glob, Printf, JLD2, CSV, OhMyREPL

<span class=hljs-keyword >let</span> N = <span class=hljs-number >111</span>
    D = <span class=hljs-built_in >Float16</span>[]; sizehint!(D, <span class=hljs-number >768</span> * (N * <span class=hljs-number >10</span>^<span class=hljs-number >6</span>)); L = []
    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:N
        embfile = <span class=hljs-meta >@sprintf</span> <span class=hljs-string >&quot;img_emb_%04d.h5&quot;</span> i
        metafile = <span class=hljs-meta >@sprintf</span> <span class=hljs-string >&quot;metadata_%04d.parquet&quot;</span> i
        <span class=hljs-meta >@show</span> embfile, metafile
        df = DataFrame(Parquet2.select(Parquet2.Dataset(metafile), :caption, :NSFW, :LICENSE, :url), copycols=<span class=hljs-literal >false</span>)
        mask = [(!ismissing(r.NSFW) &amp;&amp; r.NSFW != <span class=hljs-string >&quot;NSFW&quot;</span>) <span class=hljs-keyword >for</span> r <span class=hljs-keyword >in</span> eachrow(df)]
        df = df[mask, :]
        X = jldopen(f-&gt;f[<span class=hljs-string >&quot;emb&quot;</span>], embfile)
        <span class=hljs-meta >@assert</span> size(X, <span class=hljs-number >1</span>) == <span class=hljs-number >768</span>
        <span class=hljs-meta >@assert</span> size(X, <span class=hljs-number >2</span>) == length(mask)
        length(L) == <span class=hljs-number >0</span> ? push!(L, df) : append!(L[<span class=hljs-number >1</span>], df)
        X = X[:, mask]
        append!(D, vec(X))
        <span class=hljs-meta >@show</span> N =&gt; (<span class=hljs-number >768</span>, length(D) ÷ <span class=hljs-number >768</span>)
        <span class=hljs-keyword >if</span> i <span class=hljs-keyword >in</span> (<span class=hljs-number >11</span>, <span class=hljs-number >33</span>, <span class=hljs-number >111</span>)
            CSV.write(<span class=hljs-string >&quot;metadata-<span class=hljs-variable >$i</span>.tsv&quot;</span>, L[<span class=hljs-number >1</span>], delim=&#x27;\t&#x27;)  <span class=hljs-comment ># you can use this file to create demos</span>
            <span class=hljs-comment ># the copy is necessary only because reshape marks the array as shared and</span>
            <span class=hljs-comment ># append! will raise errors</span>
            jldsave(<span class=hljs-string >&quot;laion2B-<span class=hljs-variable >$i</span>.h5&quot;</span>, emb=reshape(copy(D), (<span class=hljs-number >768</span>, length(D) ÷ <span class=hljs-number >768</span>)))
        <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >end</span>
<span class=hljs-keyword >end</span></code></pre>
<p>Package versions:</p>
<pre><code class="julia hljs">[<span class=hljs-number >336</span>ed68f] CSV v0<span class=hljs-number >.10</span><span class=hljs-number >.9</span>
  [a93c6f00] DataFrames v1<span class=hljs-number >.4</span><span class=hljs-number >.4</span>
  [c27321d9] Glob v1<span class=hljs-number >.3</span><span class=hljs-number >.0</span>
  [<span class=hljs-number >033835</span>bb] JLD2 v0<span class=hljs-number >.4</span><span class=hljs-number >.30</span>
  [<span class=hljs-number >5</span>fb14364] OhMyREPL v0<span class=hljs-number >.5</span><span class=hljs-number >.13</span>
  [<span class=hljs-number >98572</span>fba] Parquet2 v0<span class=hljs-number >.2</span><span class=hljs-number >.8</span></code></pre>
<p>Adjust <code>N</code> if necessary. Please recall that subset 10M contains 11 parts, 30M contains 33 parts, and 100M is composed of 111 parts.</p>
<div class=warn >Original LAION parts are distributed in <code>npz</code> format and you can load them with <code>numpy</code> or the <code>NPZ.jl</code> package when you work with Julia.</div>
<div class=page-foot >
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> sisap challenge committee. Last modified: March 06, 2023.
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
</div>
</div>
    </div>  
    
    
        <script src="/libs/highlight/highlight.min.js"></script>
<script>hljs.highlightAll();hljs.configure({tabReplace: '    '});</script>